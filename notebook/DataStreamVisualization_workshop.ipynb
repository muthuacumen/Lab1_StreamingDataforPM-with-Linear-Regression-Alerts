{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Manufacturing Robot Predictive Maintenance Workshop\n\nA real-time data streaming and visualization system for predictive maintenance of industrial manufacturing robots.\n\n## Cell 1: Import Libraries and Setup\n\nThis cell imports all required libraries and configures matplotlib to use the Qt backend for separate plot windows."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\n\n# Add src directory to Python path (notebook is in notebook/, src is at ../src/)\nproject_root = os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()) == 'notebook' else os.getcwd()\nsrc_dir = os.path.join(project_root, 'src')\nif src_dir not in sys.path:\n    sys.path.insert(0, src_dir)\n\nprint(f\"Project root: {project_root}\")\nprint(f\"Source directory: {src_dir}\")\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nfrom datetime import datetime\nimport warnings\nimport importlib\nwarnings.filterwarnings('ignore')\n\n# Use Qt or Tk backend for separate windows (NOT inline)\n# This ensures plots open in new windows\n%matplotlib qt\n\n# Set visualization style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\n# Import StreamingSimulator\nimport StreamingSimulator\nimportlib.reload(StreamingSimulator)\nfrom StreamingSimulator import StreamingSimulator\n\nprint(\"Libraries imported successfully\")\nprint(f\"Matplotlib backend: {plt.get_backend()}\")\nprint(\"Plots will appear in SEPARATE WINDOWS (not inline)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Database Configuration\n",
    "\n",
    "Configure your Neon.tech database connection.\n",
    "Sign up at https://neon.tech/ and get your connection details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Database configuration\ndb_config = {\n    'host': 'ep-polished-snow-ahx3qiod-pooler.c-3.us-east-1.aws.neon.tech',\n    'database': 'neondb',\n    'user': 'neondb_owner',\n    'password': 'npg_JlIENr3i4AbL',\n    'port': 5432,\n    'sslmode': 'require'\n}\n\n# CSV path (data/ is at project root, notebook runs from notebook/)\ncsv_path = os.path.join(project_root, 'data', 'RMBR4-2_export_test.csv')\n\n# Verify the file exists\nif os.path.exists(csv_path):\n    print(\"Configuration loaded\")\n    print(f\"CSV Path: {csv_path}\")\n    print(f\"File exists: Yes\")\nelse:\n    # Try alternative paths\n    alt_path = '../data/RMBR4-2_export_test.csv'\n    if os.path.exists(alt_path):\n        csv_path = alt_path\n        print(\"Configuration loaded (using relative path)\")\n        print(f\"CSV Path: {csv_path}\")\n        print(f\"File exists: Yes\")\n    else:\n        print(f\"ERROR: CSV file not found!\")\n        print(f\"Current working directory: {os.getcwd()}\")\n        print(f\"Tried path: {csv_path}\")\n        print(\"\\nPlease ensure the CSV file is in the 'data' folder\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 1: Data Collection Mechanism - Streaming Simulation\n\n### Manufacturing Robot Controller Data Streaming System\n\n**Real-world Context:**\n\nIn industrial robotics, controllers continuously monitor current draw across multiple axes (motors). Each axis represents a degree of freedom:\n- **Axis #1-3**: Primary movement (X, Y, Z positioning)\n- **Axis #4-6**: Rotational movements (pitch, roll, yaw)\n- **Axis #7-14**: Tool-specific axes (grippers, welders, etc.)\n\n**Current measurements indicate:**\n- Motor load and workload\n- Mechanical resistance (wear, misalignment)\n- Electrical issues (shorts, overheating)\n- Operational efficiency\n\n**This simulation:**\n1. Loads 39,000+ records from the robot controller CSV\n2. Batch loads data to cloud database (Neon.tech PostgreSQL)\n3. Streams data 1 point at a time from database for real-time visualization\n4. Visualizes 8 critical axes in real-time dashboard\n5. Monitors current draw patterns across all 14 axes\n\n**Key Features:**\n- **Non-blocking visualization**: GUI remains responsive during streaming\n- **Close-to-stop**: Click the plot window's X button to stop streaming\n- **Single-point streaming**: True real-time visualization (1 record at a time)\n- **Optional GPU acceleration**: Install CuPy for faster processing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Streaming Simulator\n",
    "print(\"Initializing Streaming Simulator...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ss = StreamingSimulator(csv_path=csv_path, db_config=db_config)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Simulator Initialized Successfully!\n",
    "\n",
    "Dataset Information:\n",
    "- Total records loaded: {len(ss.df):,}\n",
    "- Number of robot axes: {len(ss.axis_columns)}\n",
    "- Axes detected: {', '.join(ss.axis_columns)}\n",
    "- Current position: {ss.current_index}\n",
    "- Database: Connected and table created\n",
    "- Time span: {ss.df['Time'].max() - ss.df['Time'].min()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 3: Stream Data from Database\n\n### Two-Phase Streaming Process:\n\n**Phase 1: Batch Load to Database**\n- Loads all CSV records into the PostgreSQL database using optimized batch inserts\n- Uses execute_values for maximum throughput (~10,000+ records/second)\n\n**Phase 2: Real-Time Database Streaming (1 Point at a Time)**\n- Fetches **exactly 1 record** per database call for true real-time streaming\n- Updates visualization after **every single point**\n- Uses **non-blocking visualization** to keep GUI responsive\n- **Close the plot window** to stop streaming at any time\n\n### Streaming Parameters:\n```python\nss.stream_from_db(\n    visualize_every=1,    # Update plot every N points (1 = every point)\n    plot_style='combined', # 'combined' or 'separate' axes view\n    fetch_size=1          # Records per DB fetch (1 = true real-time)\n)\n```\n\n### Performance Notes:\n- Single-point streaming (~10-50 pts/sec) provides smooth real-time visualization\n- For faster bulk processing, increase `fetch_size` (e.g., 100) and `visualize_every` (e.g., 50)\n\n### GPU Acceleration (Optional)\nInstall CuPy for GPU-accelerated processing:\n```bash\npip install cupy-cuda12x  # For CUDA 12.x\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Phase 1: Load all CSV data into database using optimized batch method\nprint(\"=\" * 80)\nprint(\"PHASE 1: Loading CSV data into database...\")\nprint(\"=\" * 80)\n\n# Stream ALL data points using batch processing for fast database loading\nnum_points_to_stream = len(ss.df)  # Stream entire dataset\n\nprint(f\"Target: Load {num_points_to_stream:,} data points into database\")\nprint(\"Method: Batch inserts with psycopg2 execute_values\")\nprint()\n\n# Use the optimized batch streaming method\nresult = ss.streamBatch(\n    num_points=num_points_to_stream,\n    batch_size=1000,\n    visualize_every=0,  # Disable visualization during loading\n    plot_style='combined'\n)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(f\"Database loaded: {ss.current_index:,} data points\")\nprint(\"=\" * 80)\n\n# Reset simulator for database streaming\nss.reset()\n\n# Get total records from database\ndb_count = ss.get_db_record_count()\nprint(f\"\\nRecords in database: {db_count:,}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PHASE 2: Streaming from database (1 point at a time)...\")\nprint(\"=\" * 80)\nprint(\"\\nPlots will open in a SEPARATE WINDOW\")\nprint(\"Close the plot window to stop streaming\")\nprint(\"Press Ctrl+C (or interrupt kernel) to stop early\\n\")\n\n# Check if GPU is available\nfrom StreamingSimulator import GPU_AVAILABLE\nif GPU_AVAILABLE:\n    print(\"GPU detected! Using GPU-accelerated streaming...\")\n    summary = ss.stream_from_db_gpu(visualize_every=1, plot_style='combined', batch_size=1)\nelse:\n    print(\"Streaming 1 point at a time with real-time visualization...\")\n    # Stream 1 point at a time for true real-time visualization\n    # fetch_size=1 means each database call fetches exactly 1 record\n    # visualize_every=1 means update the plot after every single point\n    summary = ss.stream_from_db(visualize_every=1, plot_style='combined', fetch_size=1)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"STREAMING COMPLETE\")\nprint(\"=\" * 80)\nif summary:\n    print(f\"Points processed: {summary['points_processed']:,}\")\n    print(f\"Buffer size: {len(ss.data_buffer):,} records\")\n    print(f\"Total time: {summary['elapsed_seconds']:.1f} seconds\")\n    print(f\"Rate: {summary['points_per_second']:.1f} points/second\")\n    if summary.get('gpu_accelerated'):\n        print(\"Acceleration: GPU (CuPy)\")\n    if summary.get('stopped_early'):\n        print(\"Status: Stopped early by user\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Data Source Documentation\n",
    "\n",
    "### Robot Controller Multi-Axis Current Monitoring Data\n",
    "\n",
    "**Data Source Overview:**\n",
    "\n",
    "This dataset contains real-time current measurements from an industrial manufacturing robot controller. The robot operates in a production environment performing precision assembly, welding, or material handling tasks.\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- **Total Records**: 39,000+ sensor readings\n",
    "- **Collection Period**: Continuous operational monitoring\n",
    "- **Sampling Frequency**: Variable (approximately 1-5 second intervals)\n",
    "- **Data Type**: Multi-axis motor current measurements\n",
    "- **Format**: CSV with tab-separated values\n",
    "\n",
    "**Data Schema:**\n",
    "\n",
    "| Field       | Type      | Description                                    | Unit    |\n",
    "|-------------|-----------|------------------------------------------------|---------|\n",
    "| Trait       | String    | Measurement type (always \"current\")            | -       |\n",
    "| Axis #1-14  | Float     | Current draw for each robot axis               | Amperes |\n",
    "| Time        | DateTime  | ISO 8601 timestamp of measurement              | -       |\n",
    "\n",
    "**Axis Configuration:**\n",
    "\n",
    "- **Axes 1-3**: Primary Linear Motors (X, Y, Z positioning)\n",
    "  - Control base movement and positioning\n",
    "  - Typical range: 0-30A\n",
    "  - Critical for precision placement\n",
    "\n",
    "- **Axes 4-6**: Rotational Joints (Wrist/Elbow rotation)\n",
    "  - Enable angular positioning\n",
    "  - Typical range: 0-15A\n",
    "  - Important for orientation tasks\n",
    "\n",
    "- **Axes 7-8**: Tool Control (End effector, gripper)\n",
    "  - Operate specialized tools\n",
    "  - Typical range: 0-10A\n",
    "  - Task-specific current patterns\n",
    "\n",
    "- **Axes 9-14**: Auxiliary/Reserved\n",
    "  - Additional DOF for complex robots\n",
    "  - May be null for simpler configurations\n",
    "  - Used in 6+ axis robots\n",
    "\n",
    "**Current Measurement Significance:**\n",
    "\n",
    "1. **Mechanical Load**: Higher current = higher resistance/load\n",
    "2. **Wear Detection**: Increasing current over time suggests bearing wear\n",
    "3. **Misalignment**: Erratic current patterns indicate mechanical issues\n",
    "4. **Efficiency**: Consistent current = healthy motor operation\n",
    "5. **Anomalies**: Spikes/drops signal potential failures\n",
    "\n",
    "**Use Case Applications:**\n",
    "- Predictive maintenance scheduling\n",
    "- Motor health monitoring\n",
    "- Energy consumption optimization\n",
    "- Workload balancing across axes\n",
    "- Failure prevention (before catastrophic breakdown)\n",
    "- Quality assurance (detect anomalies during production)\n",
    "\n",
    "**Data Quality Considerations:**\n",
    "- Some axes may have NULL values (not all robots use all 14 axes)\n",
    "- Timestamps may have irregular intervals due to event-driven logging\n",
    "- Current values of 0 may indicate idle state or sensor issues\n",
    "- Outliers may represent legitimate peak loads or sensor errors\n",
    "\n",
    "---\n",
    "\n",
    "**Query Test 1:** \"What current patterns in specific axes indicate impending motor failure or mechanical issues?\"\n",
    "\n",
    "**Query Test 2:** \"How can we correlate current anomalies across multiple axes to predict system-wide maintenance needs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive dataset information\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET DETAILED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. DATASET STRUCTURE\")\n",
    "print(\"-\" * 80)\n",
    "print(ss.df.info())\n",
    "\n",
    "print(\"\\n2. FIRST 10 RECORDS (Raw Data)\")\n",
    "print(\"-\" * 80)\n",
    "print(ss.df.head(10).to_string())\n",
    "\n",
    "print(\"\\n3. STATISTICAL SUMMARY (All Axes)\")\n",
    "print(\"-\" * 80)\n",
    "print(ss.df[ss.axis_columns].describe().to_string())\n",
    "\n",
    "print(\"\\n4. DATA COMPLETENESS CHECK\")\n",
    "print(\"-\" * 80)\n",
    "for axis in ss.axis_columns:\n",
    "    null_count = ss.df[axis].isna().sum()\n",
    "    null_pct = (null_count / len(ss.df)) * 100\n",
    "    print(f\"{axis}: {null_count:,} nulls ({null_pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n5. TIME DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "time_diff = ss.df['Time'].diff().describe()\n",
    "print(f\"Average interval: {time_diff['mean']}\")\n",
    "print(f\"Min interval: {time_diff['min']}\")\n",
    "print(f\"Max interval: {time_diff['max']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 4: Comprehensive Data Visualization\n\nStatic visualizations of the complete dataset including:\n- Current distribution histograms for all 14 axes\n- Time series plots for primary 8 axes\n- Correlation heatmap between axes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GENERATING COMPREHENSIVE VISUALIZATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Visualization 1: Current Distribution Across All Axes\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
    "fig.suptitle('Current Distribution Across All 14 Robot Axes', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, axis in enumerate(ss.axis_columns):\n",
    "    row = idx // 5\n",
    "    col = idx % 5\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    data = ss.df[axis].dropna()\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        ax.hist(data, bins=50, color=f'C{idx}', alpha=0.7, edgecolor='black')\n",
    "        ax.axvline(data.mean(), color='red', linestyle='--', \n",
    "                   linewidth=2, label=f'Mean: {data.mean():.2f}A')\n",
    "        ax.set_title(f'{axis}', fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Current (A)', fontsize=8)\n",
    "        ax.set_ylabel('Frequency', fontsize=8)\n",
    "        ax.legend(fontsize=7)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[2, 4].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Time Series Overview (First 500 points)\n",
    "fig, axes = plt.subplots(4, 2, figsize=(18, 14))\n",
    "fig.suptitle('Current Over Time - Primary Axes (First 500 Data Points)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "sample_data = ss.df.head(500)\n",
    "primary_axes = ss.axis_columns[:8]\n",
    "\n",
    "for idx, axis in enumerate(primary_axes):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    data = sample_data[axis].dropna()\n",
    "    ax.plot(data.index, data.values, linewidth=1.5, alpha=0.8)\n",
    "    ax.set_title(f'{axis} Current Trend', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Reading Index', fontsize=9)\n",
    "    ax.set_ylabel('Current (A)', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, linestyle=':')\n",
    "    ax.axhline(data.mean(), color='red', linestyle='--', \n",
    "              linewidth=1, alpha=0.5, label=f'Mean: {data.mean():.2f}A')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Correlation Heatmap\n",
    "print(\"\\nðŸ“Š Generating correlation analysis...\")\n",
    "correlation_matrix = ss.df[ss.axis_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Current Correlation Between Robot Axes', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "Correlation Insights:\n",
    "- High positive correlation (>0.7): Axes moving together (coordinated motion)\n",
    "- High negative correlation (<-0.7): Compensating movements\n",
    "- Low correlation (~0): Independent axis operations\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 3: Anomaly Detection and Analysis\n\n### Statistical Anomaly Detection for Multi-Axis Robot Systems\n\n**Methodology:**\n\nWe employ statistical process control (SPC) methods to identify anomalies:\n- Calculate mean (Î¼) and standard deviation (Ïƒ) for each axis\n- Define control limits: Î¼ Â± 2.5Ïƒ (captures 98.76% of normal data)\n- Flag data points outside control limits as anomalies\n\n**Anomaly Categories:**\n\n1. **Positive Spikes**: Current exceeds upper threshold\n   - Indicates: Overload, jamming, mechanical resistance\n   \n2. **Negative Drops**: Current below lower threshold\n   - Indicates: Loss of load, disconnection, calibration drift\n   \n3. **High Variability**: Frequent threshold crossings\n   - Indicates: Unstable operation, vibration, loose components\n\n**GPU Acceleration (Optional):**\n\nFor large datasets, enable GPU-accelerated anomaly detection:\n```python\nanomalies = ss.detect_anomalies(threshold_multiplier=2.5, use_gpu=True)\n```\nRequires CuPy: `pip install cupy-cuda12x`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ANOMALY DETECTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "anomalies = ss.detect_anomalies(threshold_multiplier=2.5)\n",
    "\n",
    "if not anomalies:\n",
    "    print(\"\\nâœ… NO ANOMALIES DETECTED in current data stream\")\n",
    "    print(\"All axes operating within normal parameters.\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  ANOMALIES DETECTED: {len(anomalies)} axes affected\\n\")\n",
    "    \n",
    "    for axis, details in anomalies.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ” {axis} - {details['severity']} SEVERITY\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"   Anomaly Count: {len(details['indices'])} occurrences\")\n",
    "        print(f\"   Mean Current: {details['mean']:.3f} A\")\n",
    "        print(f\"   Std Deviation: {details['std']:.3f} A\")\n",
    "        print(f\"   Upper Threshold: {details['threshold_upper']:.3f} A\")\n",
    "        print(f\"   Lower Threshold: {details['threshold_lower']:.3f} A\")\n",
    "        print(f\"   Anomalous Readings:\")\n",
    "        \n",
    "        for i, (idx, val) in enumerate(zip(details['indices'][:5], \n",
    "                                           details['values'][:5])):\n",
    "            print(f\"      [{i+1}] Index {idx}: {val:.3f} A \" + \n",
    "                  f\"({'â†‘' if val > details['threshold_upper'] else 'â†“'} \" +\n",
    "                  f\"{abs(val - details['mean']):.2f}A from mean)\")\n",
    "        \n",
    "        if len(details['indices']) > 5:\n",
    "            print(f\"      ... and {len(details['indices']) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 5: Axis Health Analysis\n\nAnalyzes the health status of each robot axis based on:\n- Mean current draw\n- Standard deviation\n- Coefficient of variation (CV)\n- Maximum current\n\n**Health Status Levels:**\n- **NORMAL** (Green): CV < 30%, max current < 30A\n- **CAUTION** (Orange): Max current > 30A\n- **WARNING** (Yellow): CV > 30%\n- **CRITICAL** (Red): CV > 50%"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ROBOT AXIS HEALTH ASSESSMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "health_report = ss.analyze_axis_health()\n",
    "\n",
    "if health_report:\n",
    "    print(f\"\\nAnalyzing {len(health_report)} active axes...\\n\")\n",
    "    \n",
    "    for axis, metrics in sorted(health_report.items()):\n",
    "        print(f\"{metrics['color']} {axis}: {metrics['status']}\")\n",
    "        print(f\"   Mean Current: {metrics['mean_current']:.3f} A\")\n",
    "        print(f\"   Std Deviation: {metrics['std_current']:.3f} A\")\n",
    "        print(f\"   Max Current: {metrics['max_current']:.3f} A\")\n",
    "        print(f\"   Variability (CV): {metrics['coefficient_of_variation']:.1f}%\")\n",
    "        print(f\"   Data Points: {metrics['data_points']}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}