{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Predictive Maintenance with Linear Regression Alerts\n",
    "\n",
    "## Manufacturing Robot Current Monitoring - Failure Prediction System\n",
    "\n",
    "This notebook implements a Predictive Maintenance Alert System using Linear Regression models to detect anomalies and predict failures in industrial robot current data.\n",
    "\n",
    "### Workflow:\n",
    "1. **Database Integration** - Connect to Neon.tech PostgreSQL, ingest training data\n",
    "2. **Model Training** - Fit univariate linear regression for each axis (Time → Current)\n",
    "3. **Residual Analysis** - Analyze prediction errors to discover thresholds\n",
    "4. **Alert System** - Implement ALERT/ERROR detection based on sustained deviations\n",
    "5. **Testing** - Process synthetic failure data and log events\n",
    "6. **Visualization** - Generate alert dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()) == 'notebook' else os.getcwd()\n",
    "src_dir = os.path.join(project_root, 'src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.insert(0, src_dir)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Source directory: {src_dir}\")\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use Qt backend for separate windows\n",
    "%matplotlib qt\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import custom modules\n",
    "from database_utils import (connect_to_db, create_training_table, \n",
    "                            ingest_training_data, query_training_data,\n",
    "                            get_training_record_count, create_alerts_table,\n",
    "                            clear_training_table)\n",
    "from linear_regression_model import RobotRegressionModels\n",
    "from alert_system import AlertSystem, AlertThresholds\n",
    "\n",
    "print(\"\\nLibraries imported successfully\")\n",
    "print(f\"Matplotlib backend: {plt.get_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db-header",
   "metadata": {},
   "source": [
    "## Cell 2: Database Integration\n",
    "\n",
    "Connect to Neon.tech PostgreSQL and ingest training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "database-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration (Neon.tech PostgreSQL)\n",
    "db_config = {\n",
    "    'host': 'ep-polished-snow-ahx3qiod-pooler.c-3.us-east-1.aws.neon.tech',\n",
    "    'database': 'neondb',\n",
    "    'user': 'neondb_owner',\n",
    "    'password': 'npg_JlIENr3i4AbL',\n",
    "    'port': 5432,\n",
    "    'sslmode': 'require'\n",
    "}\n",
    "\n",
    "# Training data path\n",
    "training_csv_path = os.path.join(project_root, 'data', 'robots_combined_traindata.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATABASE INTEGRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Connect to database\n",
    "conn = connect_to_db(db_config)\n",
    "\n",
    "# Create tables\n",
    "create_training_table(conn)\n",
    "create_alerts_table(conn)\n",
    "\n",
    "# Check existing records\n",
    "existing_count = get_training_record_count(conn)\n",
    "print(f\"\\nExisting training records in database: {existing_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ingest-data",
   "metadata": {},
   "outputs": [],
   "source": "# Ingest training data (only if table is empty or needs refresh)\nFORCE_REINGEST = True  # Set to True to reload data after regenerating CSVs\n\nif existing_count == 0 or FORCE_REINGEST:\n    if FORCE_REINGEST and existing_count > 0:\n        print(\"Clearing existing training data...\")\n        clear_training_table(conn)\n    \n    print(f\"\\nIngesting training data from: {training_csv_path}\")\n    records_ingested = ingest_training_data(conn, training_csv_path)\n    print(f\"Total records ingested: {records_ingested:,}\")\nelse:\n    print(f\"Using existing {existing_count:,} records in database\")\n    print(\"(Set FORCE_REINGEST=True to reload data)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-training-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query training data from database\n",
    "print(\"\\nQuerying training data from database...\")\n",
    "df_training = query_training_data(conn, robot_name='Robot A')  # Use Robot A as baseline\n",
    "\n",
    "print(f\"\\nTraining Data Shape: {df_training.shape}\")\n",
    "print(f\"Columns: {list(df_training.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Cell 3: Model Training\n",
    "\n",
    "Fit univariate linear regression for each axis:\n",
    "- **Model**: y = slope × time_index + intercept\n",
    "- **Axes**: axis_1 through axis_12 (all 12 axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train regression models for all 12 axes\n",
    "models = RobotRegressionModels()\n",
    "model_params = models.train_all_axes(df_training)\n",
    "\n",
    "# Display model summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL PARAMETERS SUMMARY (All 12 Axes)\")\n",
    "print(\"=\" * 70)\n",
    "model_summary = models.get_model_summary()\n",
    "print(model_summary.to_string())\n",
    "\n",
    "# Save model parameters\n",
    "params_path = os.path.join(project_root, 'data', 'model_params.csv')\n",
    "models.save_model_params(params_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-plots-header",
   "metadata": {},
   "source": [
    "## Cell 4: Regression Visualization\n",
    "\n",
    "Scatter plots with regression lines for all 12 axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regression lines for training data (all 12 axes)\n",
    "print(\"Generating regression plots for all 12 axes...\")\n",
    "fig_regression = models.plot_regression_lines(\n",
    "    df_training, \n",
    "    title_prefix=\"Training Data: \",\n",
    "    save_path=os.path.join(project_root, 'alerts', 'regression_lines.png')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residual-header",
   "metadata": {},
   "source": [
    "## Cell 5: Residual Analysis\n",
    "\n",
    "Analyze residuals (observed - predicted) to:\n",
    "1. Understand prediction error distribution\n",
    "2. Identify outlier patterns\n",
    "3. Determine appropriate thresholds for alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residual-histograms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual distributions for all 12 axes\n",
    "print(\"Generating residual analysis plots...\")\n",
    "fig_residuals = models.plot_residual_analysis(\n",
    "    df_training,\n",
    "    save_path=os.path.join(project_root, 'alerts', 'residual_histograms.png')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residual-boxplots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual boxplots for outlier identification\n",
    "fig_boxplots = models.plot_residual_boxplots(\n",
    "    df_training,\n",
    "    save_path=os.path.join(project_root, 'alerts', 'residual_boxplots.png')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residual-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute detailed residual statistics for all 12 axes\n",
    "print(\"=\" * 70)\n",
    "print(\"RESIDUAL STATISTICS (All 12 Axes)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "time_index = np.arange(len(df_training))\n",
    "residual_stats = []\n",
    "\n",
    "for axis_name in models.AXIS_NAMES:\n",
    "    if axis_name in df_training.columns and models.models[axis_name].is_fitted:\n",
    "        residuals = models.models[axis_name].get_residuals(time_index, df_training[axis_name])\n",
    "        residuals = residuals[~np.isnan(residuals)]\n",
    "        \n",
    "        if len(residuals) > 0:\n",
    "            stats = {\n",
    "                'axis': axis_name,\n",
    "                'mean': np.mean(residuals),\n",
    "                'std': np.std(residuals),\n",
    "                'min': np.min(residuals),\n",
    "                'max': np.max(residuals),\n",
    "                'q1': np.percentile(residuals, 25),\n",
    "                'median': np.median(residuals),\n",
    "                'q3': np.percentile(residuals, 75),\n",
    "                'p95': np.percentile(residuals, 95),\n",
    "                'p99': np.percentile(residuals, 99)\n",
    "            }\n",
    "            residual_stats.append(stats)\n",
    "        else:\n",
    "            print(f\"  {axis_name}: No valid data\")\n",
    "    else:\n",
    "        print(f\"  {axis_name}: No model fitted (no data)\")\n",
    "\n",
    "if residual_stats:\n",
    "    df_residual_stats = pd.DataFrame(residual_stats).round(4)\n",
    "    print(df_residual_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threshold-header",
   "metadata": {},
   "source": [
    "## Cell 6: Threshold Discovery & Justification\n",
    "\n",
    "Based on residual analysis, define alert thresholds:\n",
    "\n",
    "- **MinC**: Minimum deviation for ALERT (scaled by residual_std)\n",
    "- **MaxC**: Maximum deviation for ERROR (scaled by residual_std)\n",
    "- **T**: Minimum sustained duration in seconds\n",
    "\n",
    "### Justification:\n",
    "\n",
    "1. **MinC = 2.0**: Values exceeding 2σ from the regression line represent approximately 5% of normal variance (beyond 95% confidence interval). In predictive maintenance, this indicates early signs of degradation.\n",
    "\n",
    "2. **MaxC = 3.0**: Values exceeding 3σ represent less than 0.3% of normal variance (beyond 99.7% confidence interval). This level indicates significant deviation requiring immediate attention.\n",
    "\n",
    "3. **T = 30 seconds**: Transient spikes are common during robot operation cycles. A 30-second sustained deviation filters out momentary fluctuations while capturing genuine degradation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-thresholds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds based on residual analysis\n",
    "print(\"=\" * 70)\n",
    "print(\"THRESHOLD CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Thresholds (multipliers of residual standard deviation)\n",
    "MinC = 2.0   # Alert threshold: 2σ above regression\n",
    "MaxC = 3.0   # Error threshold: 3σ above regression  \n",
    "T = 30       # Sustained duration: 30 seconds\n",
    "\n",
    "thresholds = AlertThresholds(MinC=MinC, MaxC=MaxC, T=T)\n",
    "print(f\"\\nAlert Thresholds: {thresholds}\")\n",
    "\n",
    "print(f\"\\n--- THRESHOLD JUSTIFICATION ---\")\n",
    "print(f\"\"\"\\nMinC = {MinC} (Alert Threshold)\n",
    "  - Values exceeding {MinC}σ from regression line\n",
    "  - Represents ~{100 - 95.45:.1f}% of normal variance (beyond 95% CI)\n",
    "  - Indicates: Early signs of potential degradation\n",
    "  - Action: Schedule inspection, monitor closely\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"MaxC = {MaxC} (Error Threshold)\n",
    "  - Values exceeding {MaxC}σ from regression line\n",
    "  - Represents ~{100 - 99.73:.2f}% of normal variance (beyond 99.7% CI)\n",
    "  - Indicates: Significant anomaly, potential failure imminent\n",
    "  - Action: Immediate attention required\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"T = {T} seconds (Sustained Duration)\n",
    "  - Deviation must persist for {T} consecutive seconds\n",
    "  - Filters out momentary spikes from normal operation\n",
    "  - Based on typical robot operational cycle patterns\n",
    "  - Action: Only alert on persistent issues\n",
    "\"\"\")\n",
    "\n",
    "# Show actual threshold values per axis (only for fitted models)\n",
    "print(\"\\nActual threshold values per axis (in normalized units):\")\n",
    "for axis_name in models.AXIS_NAMES:\n",
    "    if models.models[axis_name].is_fitted:\n",
    "        std = models.models[axis_name].residual_std\n",
    "        print(f\"  {axis_name}: ALERT >= {MinC * std:.4f}, ERROR >= {MaxC * std:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {axis_name}: No model (no data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-header",
   "metadata": {},
   "source": [
    "## Cell 7: Alert System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-alerts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize alert system\n",
    "alert_system = AlertSystem(models, thresholds)\n",
    "\n",
    "print(\"Alert System initialized\")\n",
    "print(f\"Thresholds: {alert_system.thresholds}\")\n",
    "print(f\"Monitoring axes: {alert_system.AXIS_NAMES}\")\n",
    "\n",
    "# Create output directories\n",
    "logs_dir = os.path.join(project_root, 'logs')\n",
    "alerts_dir = os.path.join(project_root, 'alerts')\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "os.makedirs(alerts_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Logs directory: {logs_dir}\")\n",
    "print(f\"Alerts directory: {alerts_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing-header",
   "metadata": {},
   "source": [
    "## Cell 8: Streaming Test Simulation\n",
    "\n",
    "Process the synthetic test data (`robots_combined_v2.csv`) which contains injected failure behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-test-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data (with injected failures)\n",
    "test_csv_path = os.path.join(project_root, 'data', 'robots_combined_v2.csv')\n",
    "print(f\"Loading test data from: {test_csv_path}\")\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "print(f\"\\nTest Data Shape: {df_test.shape}\")\n",
    "print(f\"Columns: {list(df_test.columns)}\")\n",
    "print(f\"Robots in test data: {df_test['robot'].unique()}\")\n",
    "print(f\"\\nTest data sample:\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-test-data",
   "metadata": {},
   "outputs": [],
   "source": "# Process test data through alert system\n# Using ALL test data for complete analysis\nprint(f\"Processing all {len(df_test):,} test records...\")\n\n# Process streaming data\nalerts_detected = alert_system.process_streaming_data(df_test, time_interval_seconds=1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display alert summary\n",
    "print(\"=\" * 70)\n",
    "print(\"ALERT DETECTION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTotal events logged: {len(alert_system.alert_log)}\")\n",
    "\n",
    "if alert_system.alert_log:\n",
    "    # Count by type\n",
    "    alert_count = len([e for e in alert_system.alert_log if e.event_type == 'ALERT'])\n",
    "    error_count = len([e for e in alert_system.alert_log if e.event_type == 'ERROR'])\n",
    "    \n",
    "    print(f\"  - ALERTs: {alert_count}\")\n",
    "    print(f\"  - ERRORs: {error_count}\")\n",
    "    \n",
    "    print(\"\\nSummary by Axis:\")\n",
    "    summary = alert_system.get_alert_summary()\n",
    "    print(summary.to_string())\n",
    "    \n",
    "    print(\"\\nSample Events:\")\n",
    "    for event in alert_system.alert_log[:5]:\n",
    "        print(f\"  {event}\")\n",
    "else:\n",
    "    print(\"\\nNo alerts detected in test data.\")\n",
    "    print(\"Consider adjusting thresholds or using more test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logging-header",
   "metadata": {},
   "source": [
    "## Cell 9: Event Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-logs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save alert log to CSV\n",
    "log_path = os.path.join(logs_dir, 'alert_log.csv')\n",
    "alert_system.save_log_to_csv(log_path)\n",
    "\n",
    "# Display the saved log\n",
    "if os.path.exists(log_path):\n",
    "    df_log = pd.read_csv(log_path)\n",
    "    print(f\"\\nLog file preview ({len(df_log)} records):\")\n",
    "    print(df_log.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## Cell 10: Alert Dashboard Visualization\n",
    "\n",
    "Generate comprehensive dashboard showing all 12 axes with alert/error markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-dashboard",
   "metadata": {},
   "outputs": [],
   "source": "# Generate comprehensive dashboard for all 12 axes\nprint(\"Generating alert dashboard for all 12 axes...\")\ndashboard_path = os.path.join(alerts_dir, 'alert_dashboard.png')\nfig_dashboard = alert_system.generate_alert_dashboard(df_test, save_path=dashboard_path)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "final-header",
   "metadata": {},
   "source": [
    "## Cell 11: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": "# Count fitted models\nfitted_models = len([m for m in models.models.values() if m.is_fitted])\n\nprint(\"=\" * 70)\nprint(\"PREDICTIVE MAINTENANCE ANALYSIS COMPLETE\")\nprint(\"=\" * 70)\n\nprint(f\"\"\"\nSUMMARY:\n--------\nTraining Data: {len(df_training):,} records from database\nTest Data: {len(df_test):,} records processed\nModels Trained: {fitted_models} / 12 axes (axes with data)\n\nTHRESHOLDS:\n-----------\nMinC (Alert): {thresholds.MinC}σ above regression\nMaxC (Error): {thresholds.MaxC}σ above regression\nT (Duration): {thresholds.T} seconds sustained\n\nRESULTS:\n--------\nTotal Events Detected: {len(alert_system.alert_log)}\n  - ALERTs: {len([e for e in alert_system.alert_log if e.event_type == 'ALERT'])}\n  - ERRORs: {len([e for e in alert_system.alert_log if e.event_type == 'ERROR'])}\n\nOUTPUT FILES:\n-------------\n- Model Parameters: data/model_params.csv\n- Alert Log: logs/alert_log.csv\n- Regression Plot: alerts/regression_lines.png\n- Residual Analysis: alerts/residual_histograms.png\n- Residual Boxplots: alerts/residual_boxplots.png\n- Alert Dashboard: alerts/alert_dashboard.png\n\"\"\")\n\n# Close database connection\nconn.close()\nprint(\"\\nDatabase connection closed.\")\nprint(\"\\n\" + \"=\" * 70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}