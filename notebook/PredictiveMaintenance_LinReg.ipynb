{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Predictive Maintenance with Linear Regression Alerts\n",
    "\n",
    "## Manufacturing Robot Current Monitoring - Failure Prediction System\n",
    "\n",
    "This notebook implements a Predictive Maintenance Alert System using Linear Regression models to detect anomalies and predict failures in industrial robot current data.\n",
    "\n",
    "### Workflow:\n",
    "1. **Database Integration** - Connect to Neon.tech PostgreSQL, ingest training data\n",
    "2. **Model Training** - Fit univariate linear regression for each axis (Time → Current)\n",
    "3. **Residual Analysis** - Analyze prediction errors to discover thresholds\n",
    "4. **Alert System** - Implement ALERT/ERROR detection based on sustained deviations\n",
    "5. **Testing** - Process synthetic failure data and log events\n",
    "6. **Visualization** - Generate alert dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Projects\\Lab1_StreamingDataforPMwithLinRegAlerts\n",
      "Source directory: c:\\Projects\\Lab1_StreamingDataforPMwithLinRegAlerts\\src\n",
      "\n",
      "Libraries imported successfully\n",
      "Matplotlib backend: qtagg\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()) == 'notebook' else os.getcwd()\n",
    "src_dir = os.path.join(project_root, 'src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.insert(0, src_dir)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Source directory: {src_dir}\")\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use Qt backend for separate windows\n",
    "%matplotlib qt\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import custom modules (force reload to pick up any source changes)\n",
    "import database_utils\n",
    "import linear_regression_model\n",
    "import alert_system\n",
    "importlib.reload(database_utils)\n",
    "importlib.reload(linear_regression_model)\n",
    "importlib.reload(alert_system)\n",
    "\n",
    "from database_utils import (connect_to_db, create_training_table, \n",
    "                            ingest_training_data, query_training_data,\n",
    "                            get_training_record_count, create_alerts_table,\n",
    "                            clear_training_table, drop_training_table)\n",
    "from linear_regression_model import RobotRegressionModels\n",
    "from alert_system import AlertSystem, AlertThresholds\n",
    "\n",
    "print(\"\\nLibraries imported successfully\")\n",
    "print(f\"Matplotlib backend: {plt.get_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db-header",
   "metadata": {},
   "source": [
    "## Cell 2: Database Integration\n",
    "\n",
    "Connect to Neon.tech PostgreSQL and ingest training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "database-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATABASE INTEGRATION\n",
      "======================================================================\n",
      "Connected to database: neondb @ ep-polished-snow-ahx3qiod-pooler.c-3.us-east-1.aws.neon.tech\n",
      "Training data table created/verified\n",
      "Alerts table created/verified\n",
      "\n",
      "Existing training records in database: 40,000\n"
     ]
    }
   ],
   "source": [
    "# Database configuration (Neon.tech PostgreSQL)\n",
    "db_config = {\n",
    "    'host': 'ep-polished-snow-ahx3qiod-pooler.c-3.us-east-1.aws.neon.tech',\n",
    "    'database': 'neondb',\n",
    "    'user': 'neondb_owner',\n",
    "    'password': 'npg_JlIENr3i4AbL',\n",
    "    'port': 5432,\n",
    "    'sslmode': 'require'\n",
    "}\n",
    "\n",
    "# Training data path\n",
    "training_csv_path = os.path.join(project_root, 'data', 'robots_combined_traindata.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATABASE INTEGRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Connect to database\n",
    "conn = connect_to_db(db_config)\n",
    "\n",
    "# Create tables\n",
    "create_training_table(conn)\n",
    "create_alerts_table(conn)\n",
    "\n",
    "# Check existing records\n",
    "existing_count = get_training_record_count(conn)\n",
    "print(f\"\\nExisting training records in database: {existing_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ingest-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping and recreating training table (schema refresh)...\n",
      "Training table dropped\n",
      "Training data table created/verified\n",
      "\n",
      "Ingesting training data from: c:\\Projects\\Lab1_StreamingDataforPMwithLinRegAlerts\\data\\robots_combined_traindata.csv\n",
      "Loading training data from: c:\\Projects\\Lab1_StreamingDataforPMwithLinRegAlerts\\data\\robots_combined_traindata.csv\n",
      "Loaded 40,000 records from CSV\n",
      "  Inserted 10,000 / 40,000 records\n",
      "  Inserted 20,000 / 40,000 records\n",
      "  Inserted 30,000 / 40,000 records\n",
      "  Inserted 40,000 / 40,000 records\n",
      "Ingestion complete: 40,000 records\n",
      "Total records ingested: 40,000\n"
     ]
    }
   ],
   "source": [
    "# Ingest training data (only if table is empty or needs refresh)\n",
    "FORCE_REINGEST = True  # Set to True to reload data after regenerating CSVs\n",
    "\n",
    "if existing_count == 0 or FORCE_REINGEST:\n",
    "    if FORCE_REINGEST:\n",
    "        print(\"Dropping and recreating training table (schema refresh)...\")\n",
    "        drop_training_table(conn)\n",
    "        create_training_table(conn)\n",
    "    \n",
    "    print(f\"\\nIngesting training data from: {training_csv_path}\")\n",
    "    records_ingested = ingest_training_data(conn, training_csv_path)\n",
    "    print(f\"Total records ingested: {records_ingested:,}\")\n",
    "else:\n",
    "    print(f\"Using existing {existing_count:,} records in database\")\n",
    "    print(\"(Set FORCE_REINGEST=True to reload data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-training-data",
   "metadata": {},
   "outputs": [],
   "source": "# Robot configuration: name -> number of active axes\nROBOT_CONFIG = {\n    'Robot A': 8,\n    'Robot B': 10,\n    'Robot C': 12,\n    'Robot D': 12,\n}\n\n# Query training data per robot from database\nprint(\"\\nQuerying training data per robot from database...\")\nprint(\"=\" * 70)\n\ntraining_data = {}  # robot_name -> DataFrame\n\nfor robot_name, n_axes in ROBOT_CONFIG.items():\n    df_robot = query_training_data(conn, robot_name=robot_name)\n    # Drop columns that are entirely NaN (axes this robot doesn't have)\n    df_robot = df_robot.dropna(axis=1, how='all')\n    training_data[robot_name] = df_robot\n\n    active_axes = [c for c in df_robot.columns if c.startswith('axis_')]\n    print(f\"\\n{robot_name}: {df_robot.shape[0]:,} records, \"\n          f\"{len(active_axes)} active axes {active_axes}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(f\"Total robots loaded: {len(training_data)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": "## Cell 3: Model Training\n\nFit univariate linear regression per robot, per axis:\n- **Model**: y = slope × time_index + intercept\n- **Each robot** gets its own `RobotRegressionModels` instance\n- Only axes with data are fitted (NaN-only axes are skipped automatically)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-models",
   "metadata": {},
   "outputs": [],
   "source": "# Train per-robot regression models\nrobot_models = {}  # robot_name -> RobotRegressionModels\nall_summaries = []\n\nfor robot_name, df_robot in training_data.items():\n    print(f\"\\n{'#' * 70}\")\n    print(f\"# {robot_name}\")\n    print(f\"{'#' * 70}\")\n\n    models = RobotRegressionModels()\n    models.train_all_axes(df_robot)\n    robot_models[robot_name] = models\n\n    # Collect summary with robot column\n    summary = models.get_model_summary()\n    summary.insert(0, 'robot', robot_name)\n    all_summaries.append(summary)\n\n# Combined model summary\ndf_all_params = pd.concat(all_summaries, ignore_index=True)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"COMBINED MODEL PARAMETERS SUMMARY\")\nprint(\"=\" * 70)\nprint(df_all_params[df_all_params['is_fitted'] == True].to_string())\n\n# Save combined model parameters\nparams_path = os.path.join(project_root, 'data', 'model_params.csv')\ndf_all_params.to_csv(params_path, index=False)\nprint(f\"\\nModel parameters saved to: {params_path}\")\n\n# Quick count\nfor robot_name, models in robot_models.items():\n    fitted = len([m for m in models.models.values() if m.is_fitted])\n    print(f\"  {robot_name}: {fitted} fitted models\")"
  },
  {
   "cell_type": "markdown",
   "id": "regression-plots-header",
   "metadata": {},
   "source": "## Cell 4: Regression Visualization\n\nScatter plots with regression lines per robot."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-regression",
   "metadata": {},
   "outputs": [],
   "source": "# Plot regression lines per robot\nprint(\"Generating per-robot regression plots...\")\n\nfor robot_name, models in robot_models.items():\n    safe_name = robot_name.replace(' ', '_')\n    save_path = os.path.join(project_root, 'alerts', f'regression_lines_{safe_name}.png')\n    fig = models.plot_regression_lines(\n        training_data[robot_name],\n        title_prefix=f\"{robot_name} Training: \",\n        save_path=save_path\n    )\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "residual-header",
   "metadata": {},
   "source": "## Cell 5: Residual Analysis\n\nAnalyze residuals (observed - predicted) per robot to:\n1. Understand prediction error distribution\n2. Identify outlier patterns\n3. Determine appropriate thresholds for alerts"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residual-histograms",
   "metadata": {},
   "outputs": [],
   "source": "# Plot residual distributions per robot\nprint(\"Generating per-robot residual histograms...\")\n\nfor robot_name, models in robot_models.items():\n    safe_name = robot_name.replace(' ', '_')\n    save_path = os.path.join(project_root, 'alerts', f'residual_histograms_{safe_name}.png')\n    fig = models.plot_residual_analysis(\n        training_data[robot_name],\n        save_path=save_path\n    )\n    fig.suptitle(f'{robot_name} - Residual Distributions', fontsize=16, fontweight='bold')\n    plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residual-boxplots",
   "metadata": {},
   "outputs": [],
   "source": "# Residual boxplots per robot\nprint(\"Generating per-robot residual boxplots...\")\n\nfor robot_name, models in robot_models.items():\n    safe_name = robot_name.replace(' ', '_')\n    save_path = os.path.join(project_root, 'alerts', f'residual_boxplots_{safe_name}.png')\n    fig = models.plot_residual_boxplots(\n        training_data[robot_name],\n        save_path=save_path\n    )\n    fig.suptitle(f'{robot_name} - Residual Boxplots', fontsize=16, fontweight='bold')\n    plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residual-statistics",
   "metadata": {},
   "outputs": [],
   "source": "# Compute detailed residual statistics per robot\nprint(\"=\" * 70)\nprint(\"RESIDUAL STATISTICS (Per Robot)\")\nprint(\"=\" * 70)\n\nall_residual_stats = []\n\nfor robot_name, models in robot_models.items():\n    df_robot = training_data[robot_name]\n    time_index = np.arange(len(df_robot))\n\n    for axis_name in models.AXIS_NAMES:\n        if axis_name in df_robot.columns and models.models[axis_name].is_fitted:\n            residuals = models.models[axis_name].get_residuals(time_index, df_robot[axis_name])\n            residuals = residuals[~np.isnan(residuals)]\n\n            if len(residuals) > 0:\n                stats = {\n                    'robot': robot_name,\n                    'axis': axis_name,\n                    'mean': np.mean(residuals),\n                    'std': np.std(residuals),\n                    'min': np.min(residuals),\n                    'max': np.max(residuals),\n                    'q1': np.percentile(residuals, 25),\n                    'median': np.median(residuals),\n                    'q3': np.percentile(residuals, 75),\n                    'p95': np.percentile(residuals, 95),\n                    'p99': np.percentile(residuals, 99)\n                }\n                all_residual_stats.append(stats)\n\nif all_residual_stats:\n    df_residual_stats = pd.DataFrame(all_residual_stats).round(4)\n    print(df_residual_stats.to_string())"
  },
  {
   "cell_type": "markdown",
   "id": "threshold-header",
   "metadata": {},
   "source": [
    "## Cell 6: Threshold Discovery & Justification\n",
    "\n",
    "Based on residual analysis, define alert thresholds:\n",
    "\n",
    "- **MinC**: Minimum deviation for ALERT (scaled by residual_std)\n",
    "- **MaxC**: Maximum deviation for ERROR (scaled by residual_std)\n",
    "- **T**: Minimum sustained duration in seconds\n",
    "\n",
    "### Justification:\n",
    "\n",
    "1. **MinC = 2.0**: Values exceeding 2σ from the regression line represent approximately 5% of normal variance (beyond 95% confidence interval). In predictive maintenance, this indicates early signs of degradation.\n",
    "\n",
    "2. **MaxC = 3.0**: Values exceeding 3σ represent less than 0.3% of normal variance (beyond 99.7% confidence interval). This level indicates significant deviation requiring immediate attention.\n",
    "\n",
    "3. **T = 30 seconds**: Transient spikes are common during robot operation cycles. A 30-second sustained deviation filters out momentary fluctuations while capturing genuine degradation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-thresholds",
   "metadata": {},
   "outputs": [],
   "source": "# Define thresholds based on residual analysis\nprint(\"=\" * 70)\nprint(\"THRESHOLD CONFIGURATION\")\nprint(\"=\" * 70)\n\n# Thresholds (multipliers of residual standard deviation)\nMinC = 2.0   # Alert threshold: 2σ above regression\nMaxC = 3.0   # Error threshold: 3σ above regression  \nT = 30       # Sustained duration: 30 seconds\n\nthresholds = AlertThresholds(MinC=MinC, MaxC=MaxC, T=T)\nprint(f\"\\nAlert Thresholds: {thresholds}\")\n\nprint(f\"\\n--- THRESHOLD JUSTIFICATION ---\")\nprint(f\"\"\"\\nMinC = {MinC} (Alert Threshold)\n  - Values exceeding {MinC}σ from regression line\n  - Represents ~{100 - 95.45:.1f}% of normal variance (beyond 95% CI)\n  - Indicates: Early signs of potential degradation\n  - Action: Schedule inspection, monitor closely\n\"\"\")\n\nprint(f\"\"\"MaxC = {MaxC} (Error Threshold)\n  - Values exceeding {MaxC}σ from regression line\n  - Represents ~{100 - 99.73:.2f}% of normal variance (beyond 99.7% CI)\n  - Indicates: Significant anomaly, potential failure imminent\n  - Action: Immediate attention required\n\"\"\")\n\nprint(f\"\"\"T = {T} seconds (Sustained Duration)\n  - Deviation must persist for {T} consecutive seconds\n  - Filters out momentary spikes from normal operation\n  - Based on typical robot operational cycle patterns\n  - Action: Only alert on persistent issues\n\"\"\")\n\n# Show actual threshold values per robot per axis\nprint(\"\\nActual threshold values per robot per axis (in normalized units):\")\nfor robot_name, models in robot_models.items():\n    print(f\"\\n  {robot_name}:\")\n    for axis_name in models.AXIS_NAMES:\n        if models.models[axis_name].is_fitted:\n            std = models.models[axis_name].residual_std\n            print(f\"    {axis_name}: ALERT >= {MinC * std:.4f}, ERROR >= {MaxC * std:.4f}\")\n        else:\n            print(f\"    {axis_name}: No model (no data)\")"
  },
  {
   "cell_type": "markdown",
   "id": "alert-header",
   "metadata": {},
   "source": [
    "## Cell 7: Alert System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-alerts",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize per-robot alert systems\nrobot_alert_systems = {}  # robot_name -> AlertSystem\n\nfor robot_name, models in robot_models.items():\n    robot_alert_systems[robot_name] = AlertSystem(models, thresholds)\n\nprint(\"Per-robot Alert Systems initialized\")\nprint(f\"Thresholds: {thresholds}\")\nfor robot_name, asys in robot_alert_systems.items():\n    fitted = len([m for m in asys.models.models.values() if m.is_fitted])\n    print(f\"  {robot_name}: monitoring {fitted} axes\")\n\n# Create output directories\nlogs_dir = os.path.join(project_root, 'logs')\nalerts_dir = os.path.join(project_root, 'alerts')\nos.makedirs(logs_dir, exist_ok=True)\nos.makedirs(alerts_dir, exist_ok=True)\n\nprint(f\"\\nLogs directory: {logs_dir}\")\nprint(f\"Alerts directory: {alerts_dir}\")"
  },
  {
   "cell_type": "markdown",
   "id": "testing-header",
   "metadata": {},
   "source": [
    "## Cell 8: Streaming Test Simulation\n",
    "\n",
    "Process the synthetic test data (`robots_combined_v2.csv`) which contains injected failure behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-test-data",
   "metadata": {},
   "outputs": [],
   "source": "# Load test data (with injected failures)\ntest_csv_path = os.path.join(project_root, 'data', 'robots_combined_v2.csv')\nprint(f\"Loading test data from: {test_csv_path}\")\n\ndf_test_all = pd.read_csv(test_csv_path)\nprint(f\"\\nTest Data Shape: {df_test_all.shape}\")\nprint(f\"Columns: {list(df_test_all.columns)}\")\nprint(f\"Robots in test data: {df_test_all['robot'].unique()}\")\nprint(f\"\\nRecords per robot:\")\nprint(df_test_all['robot'].value_counts().to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-test-data",
   "metadata": {},
   "outputs": [],
   "source": "# Process test data through per-robot alert systems\nprint(\"Processing test data per robot...\")\nprint(\"=\" * 70)\n\nfor robot_name, asys in robot_alert_systems.items():\n    df_robot_test = df_test_all[df_test_all['robot'] == robot_name].reset_index(drop=True)\n    # Drop NaN-only axis columns for this robot\n    df_robot_test = df_robot_test.dropna(axis=1, how='all')\n\n    print(f\"\\n{robot_name}: {len(df_robot_test):,} test records\")\n    asys.process_streaming_data(df_robot_test, time_interval_seconds=1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-summary",
   "metadata": {},
   "outputs": [],
   "source": "# Display combined alert summary\nprint(\"=\" * 70)\nprint(\"ALERT DETECTION RESULTS (All Robots)\")\nprint(\"=\" * 70)\n\n# Merge all alert logs\nall_events = []\nfor robot_name, asys in robot_alert_systems.items():\n    alert_count = len([e for e in asys.alert_log if e.event_type == 'ALERT'])\n    error_count = len([e for e in asys.alert_log if e.event_type == 'ERROR'])\n    print(f\"\\n{robot_name}: {len(asys.alert_log)} events \"\n          f\"(ALERTs: {alert_count}, ERRORs: {error_count})\")\n    all_events.extend(asys.alert_log)\n\nprint(f\"\\nTotal events across all robots: {len(all_events)}\")\n\nif all_events:\n    df_events = pd.DataFrame([e.to_dict() for e in all_events])\n    print(\"\\nSummary by robot, axis, event_type:\")\n    summary = df_events.groupby(['robot', 'axis', 'event_type']).agg(\n        count=('deviation', 'size'),\n        mean_deviation=('deviation', 'mean'),\n        max_deviation=('deviation', 'max'),\n        mean_duration=('duration_seconds', 'mean'),\n    ).round(3)\n    print(summary.to_string())\n\n    print(\"\\nSample Events:\")\n    for event in all_events[:5]:\n        print(f\"  {event}\")\nelse:\n    print(\"\\nNo alerts detected in test data.\")"
  },
  {
   "cell_type": "markdown",
   "id": "logging-header",
   "metadata": {},
   "source": [
    "## Cell 9: Event Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-logs",
   "metadata": {},
   "outputs": [],
   "source": "# Save combined alert log to CSV\nlog_path = os.path.join(logs_dir, 'alert_log.csv')\n\n# Combine all events from all robot alert systems\nall_events = []\nfor robot_name, asys in robot_alert_systems.items():\n    all_events.extend(asys.alert_log)\n\n# Write combined log\nif all_events:\n    df_log = pd.DataFrame([e.to_dict() for e in all_events])\n    df_log.to_csv(log_path, index=False)\n    print(f\"Combined alert log saved to: {log_path} ({len(df_log)} events)\")\n    print(f\"\\nLog file preview:\")\n    print(df_log.head(10).to_string())\nelse:\n    print(\"No events to save.\")"
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## Cell 10: Alert Dashboard Visualization\n",
    "\n",
    "Generate comprehensive dashboard showing all 12 axes with alert/error markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-dashboard",
   "metadata": {},
   "outputs": [],
   "source": "# Generate per-robot alert dashboards\nprint(\"Generating per-robot alert dashboards...\")\n\nfor robot_name, asys in robot_alert_systems.items():\n    safe_name = robot_name.replace(' ', '_')\n    dashboard_path = os.path.join(alerts_dir, f'alert_dashboard_{safe_name}.png')\n\n    # Get this robot's test data\n    df_robot_test = df_test_all[df_test_all['robot'] == robot_name].reset_index(drop=True)\n    df_robot_test = df_robot_test.dropna(axis=1, how='all')\n\n    fig = asys.generate_alert_dashboard(df_robot_test, save_path=dashboard_path)\n    fig.suptitle(f'{robot_name} - Alert Dashboard', fontsize=18, fontweight='bold')\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "final-header",
   "metadata": {},
   "source": [
    "## Cell 11: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": "# Final summary\nprint(\"=\" * 70)\nprint(\"PREDICTIVE MAINTENANCE ANALYSIS COMPLETE\")\nprint(\"=\" * 70)\n\ntotal_fitted = 0\ntotal_alerts = 0\ntotal_errors = 0\n\nprint(\"\\nPER-ROBOT BREAKDOWN:\")\nprint(\"-\" * 70)\n\nfor robot_name in ROBOT_CONFIG:\n    models = robot_models[robot_name]\n    asys = robot_alert_systems[robot_name]\n    df_train = training_data[robot_name]\n    df_robot_test = df_test_all[df_test_all['robot'] == robot_name]\n\n    fitted = len([m for m in models.models.values() if m.is_fitted])\n    alerts = len([e for e in asys.alert_log if e.event_type == 'ALERT'])\n    errors = len([e for e in asys.alert_log if e.event_type == 'ERROR'])\n\n    total_fitted += fitted\n    total_alerts += alerts\n    total_errors += errors\n\n    print(f\"\\n  {robot_name}:\")\n    print(f\"    Fitted models:  {fitted}\")\n    print(f\"    Training rows:  {len(df_train):,}\")\n    print(f\"    Test rows:      {len(df_robot_test):,}\")\n    print(f\"    ALERTs:         {alerts}\")\n    print(f\"    ERRORs:         {errors}\")\n\nprint(f\"\"\"\n{'=' * 70}\nCOMBINED TOTALS:\n  Total fitted models: {total_fitted}\n  Total training rows: {sum(len(d) for d in training_data.values()):,}\n  Total test rows:     {len(df_test_all):,}\n  Total ALERTs:        {total_alerts}\n  Total ERRORs:        {total_errors}\n\nTHRESHOLDS:\n  MinC (Alert): {thresholds.MinC}σ above regression\n  MaxC (Error): {thresholds.MaxC}σ above regression\n  T (Duration): {thresholds.T} seconds sustained\n\nOUTPUT FILES:\n  Model Parameters:     data/model_params.csv (combined, with robot column)\n  Alert Log:            logs/alert_log.csv (combined, all robots)\n  Regression Plots:     alerts/regression_lines_Robot_*.png (x{len(ROBOT_CONFIG)})\n  Residual Histograms:  alerts/residual_histograms_Robot_*.png (x{len(ROBOT_CONFIG)})\n  Residual Boxplots:    alerts/residual_boxplots_Robot_*.png (x{len(ROBOT_CONFIG)})\n  Alert Dashboards:     alerts/alert_dashboard_Robot_*.png (x{len(ROBOT_CONFIG)})\n{'=' * 70}\n\"\"\")\n\n# Close database connection\nconn.close()\nprint(\"Database connection closed.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}